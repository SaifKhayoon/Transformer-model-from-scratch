{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "using Flux\n",
    "using Knet\n",
    "using Statistics\n",
    "using CSV\n",
    "\n",
    "# Define the Transformer model and related functions\n",
    "function transformer_model()\n",
    "  # colab stuff\n",
    "using IJulia\n",
    "notebook(detached=true)\n",
    "\n",
    "# for local use AMD : ENV[\"KNET_GPU\"] = \"vulkan\"\n",
    "using Knet\n",
    "\n",
    "# Define the architecture\n",
    "struct Transformer\n",
    "    # Layer parameters\n",
    "    Wq, Wk, Wv, Wfc1, Wfc2\n",
    "    bq, bk, bv, bfc1, bfc2\n",
    "end\n",
    "\n",
    "# Initialize the model parameters\n",
    "function Transformer(input_size::Int, hidden_size::Int, num_heads::Int)\n",
    "    Wq = param(hidden_size, input_size)\n",
    "    Wk = param(hidden_size, input_size)\n",
    "    Wv = param(hidden_size, input_size)\n",
    "    Wfc1 = param(hidden_size, hidden_size)\n",
    "    Wfc2 = param(hidden_size, hidden_size)\n",
    "    bq = param0(hidden_size)\n",
    "    bk = param0(hidden_size)\n",
    "    bv = param0(hidden_size)\n",
    "    bfc1 = param0(hidden_size)\n",
    "    bfc2 = param0(hidden_size)\n",
    "    Transformer(Wq, Wk, Wv, Wfc1, Wfc2, bq, bk, bv, bfc1, bfc2)\n",
    "end\n",
    "\n",
    "# Define the self-attention function\n",
    "function self_attention(query, key, value, mask)\n",
    "    attention_weights = softmax(query * transpose(key) / sqrt(hidden_size))\n",
    "    masked_attention_weights = attention_weights .* mask\n",
    "    weighted_value = masked_attention_weights * value\n",
    "    return weighted_value\n",
    "end\n",
    "\n",
    "# Define the feedforward function\n",
    "function feedforward(x, Wfc1, bfc1, Wfc2, bfc2)\n",
    "    h = relu(x * Wfc1 .+ bfc1)\n",
    "    y = h * Wfc2 .+ bfc2\n",
    "    return y\n",
    "end\n",
    "\n",
    "# Define the forward pass function\n",
    "function (model::Transformer)(input)\n",
    "    query = input * model.Wq .+ model.bq\n",
    "    key = input * model.Wk .+ model.bk\n",
    "    value = input * model.Wv .+ model.bv\n",
    "    weighted_value = self_attention(query, key, value, mask)\n",
    "    y = feedforward(weighted_value, model.Wfc1, model.bfc1, model.Wfc2, model.bfc2)\n",
    "    return y\n",
    "end\n",
    "\n",
    "# Training the model\n",
    "function train(model, data, labels)\n",
    "    optimizer = optimizers(model, Adagrad)\n",
    "    for (x, y) in zip(data, labels)\n",
    "        # Compute the loss\n",
    "        y_pred = model(x)\n",
    "        loss = mean(abs2, y_pred - y)\n",
    "\n",
    "        # Update the model parameters\n",
    "        grads = grad(loss, params(model))\n",
    "        update!(optimizer, grads)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Evaluating the model\n",
    "function evaluate(model, data, labels)\n",
    "    accuracy = 0\n",
    "    for (x, y) in zip(data, labels)\n",
    "        y_pred = model(x)\n",
    "        accuracy += mean(y_pred .== y)\n",
    "    end\n",
    "    accuracy /= length(data)\n",
    "    return accuracy\n",
    "end\n",
    "end\n",
    "\n",
    "# Load and preprocess the dataset used to train and evaluate the model\n",
    "function dataset()\n",
    "  using JuliaDB, CSV\n",
    "\n",
    "# Load the dataset\n",
    "function load_dataset(filename)\n",
    "    data = CSV.File(filename) |> DataFrame!\n",
    "    return data\n",
    "end\n",
    "\n",
    "# Preprocess the dataset\n",
    "function preprocess_dataset(data)\n",
    "    # Normalize the input features\n",
    "    x = convert(Matrix, data[:, 1:end-1])\n",
    "    x = (x .- mean(x, dims=1)) ./ std(x, dims=1)\n",
    "\n",
    "    # Convert the labels to one-hot encoding\n",
    "    y = onehotbatch(data[:, end])\n",
    "\n",
    "    return x, y\n",
    "end\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "function split_dataset(x, y, train_ratio)\n",
    "    n = size(x, 1)\n",
    "    n_train = convert(Int, n * train_ratio)\n",
    "\n",
    "    x_train, y_train = x[1:n_train, :], y[1:n_train, :]\n",
    "    x_val, y_val = x[n_train+1:end, :], y[n_train+1:end, :]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val\n",
    "end\n",
    "using JuliaDB, CSV\n",
    "\n",
    "# Load the dataset\n",
    "function load_dataset(filename)\n",
    "    data = CSV.File(filename) |> DataFrame!\n",
    "    return data\n",
    "end\n",
    "\n",
    "# Preprocess the dataset\n",
    "function preprocess_dataset(data)\n",
    "    # Normalize the input features\n",
    "    x = convert(Matrix, data[:, 1:end-1])\n",
    "    x = (x .- mean(x, dims=1)) ./ std(x, dims=1)\n",
    "\n",
    "    # Convert the labels to one-hot encoding\n",
    "    y = onehotbatch(data[:, end])\n",
    "\n",
    "    return x, y\n",
    "end\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "function split_dataset(x, y, train_ratio)\n",
    "    n = size(x, 1)\n",
    "    n_train = convert(Int, n * train_ratio)\n",
    "\n",
    "    x_train, y_train = x[1:n_train, :], y[1:n_train, :]\n",
    "    x_val, y_val = x[n_train+1:end, :], y[n_train+1:end, :]\n",
    "\n",
    "    return x_train, y_train, x_val, y_val\n",
    "end\n",
    "\n",
    "end\n",
    "\n",
    "# Train the model using the training data\n",
    "function training()\n",
    "  using Flux, Statistics\n",
    "\n",
    "# Define the loss function\n",
    "function loss(model, x, y)\n",
    "    y_pred = model(x)\n",
    "    return Flux.crossentropy(y_pred, y)\n",
    "end\n",
    "\n",
    "# Define the accuracy metric\n",
    "function accuracy(model, x, y)\n",
    "    y_pred = model(x)\n",
    "    y_pred = onecold(y_pred)\n",
    "    y = onecold(y)\n",
    "    return mean(y_pred .== y)\n",
    "end\n",
    "\n",
    "# Train the model\n",
    "function train(model, x_train, y_train, x_val, y_val; epochs=10, lr=0.01)\n",
    "    opt = Flux.ADAM(params(model), lr=lr)\n",
    "\n",
    "    for epoch in 1:epochs\n",
    "        Flux.train!(loss, model, x_train, y_train, opt)\n",
    "\n",
    "        train_loss = mean(loss(model, x_train, y_train))\n",
    "        train_acc = accuracy(model, x_train, y_train)\n",
    "\n",
    "        val_loss = mean(loss(model, x_val, y_val))\n",
    "        val_acc = accuracy(model, x_val, y_val)\n",
    "\n",
    "        println(\"Epoch: $(epoch)\")\n",
    "        println(\"  Train Loss: $(train_loss)\")\n",
    "        println(\"  Train Acc: $(train_acc)\")\n",
    "        println(\"  Val Loss: $(val_loss)\")\n",
    "        println(\"  Val Acc: $(val_acc)\")\n",
    "    end\n",
    "end\n",
    "end\n",
    "\n",
    "# Evaluate the model using the validation data\n",
    "function evaluation()\n",
    "  using Flux, Statistics\n",
    "\n",
    "# Define the loss function\n",
    "function loss(model, x, y)\n",
    "    y_pred = model(x)\n",
    "    return Flux.crossentropy(y_pred, y)\n",
    "end\n",
    "\n",
    "# Define the accuracy metric\n",
    "function accuracy(model, x, y)\n",
    "    y_pred = model(x)\n",
    "    y_pred = onecold(y_pred)\n",
    "    y = onecold(y)\n",
    "    return mean(y_pred .== y)\n",
    "end\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "function evaluate(model, x_test, y_test)\n",
    "    test_loss = mean(loss(model, x_test, y_test))\n",
    "    test_acc = accuracy(model, x_test, y_test)\n",
    "\n",
    "    println(\"Test Loss: $(test_loss)\")\n",
    "    println(\"Test Acc: $(test_acc)\")\n",
    "end\n",
    "end\n",
    "\n",
    "# Main function to tie everything together\n",
    "function main()\n",
    "  # Import required files\n",
    "  include(\"transformer_model.jl\")\n",
    "  include(\"dataset.jl\")\n",
    "  include(\"training.jl\")\n",
    "  include(\"evaluation.jl\")\n",
    "\n",
    "  # Run the training and evaluation steps\n",
    "  using Flux, .Transformer, .Dataset, .Training, .Evaluation\n",
    "\n",
    "# Load the dataset\n",
    "x_train, y_train, x_test, y_test = load_data()\n",
    "\n",
    "# Define the model\n",
    "model = TransformerModel()\n",
    "\n",
    "# Train the model\n",
    "train(model, x_train, y_train)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "evaluate(model, x_test, y_test)\n",
    "\n",
    "end\n",
    "\n",
    "# Call the main function to run the code\n",
    "main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7 (tags/v3.10.7:6cc6b13, Sep  5 2022, 14:08:36) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a4c5f77482173d9d558957e0518288221c8e813fec962bc696be1ca310f8570"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
